{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Demo: Neural network training for denoising of *Tribolium castaneum*\n",
    "\n",
    "### Notes \n",
    "\n",
    "- Assumes that training data was already generated via [datagen.ipynb](datagen.ipynb) and has been saved to disk to the file ``my_training_data.npz``.\n",
    "- Training a neural network for actual use should be done on more (representative) data and with much more training time.\n",
    "- More documentation available (within CBG/CSBD network): http://myers-pc-8:8080/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import csbdeep\n",
    "from csbdeep import train\n",
    "from csbdeep import nets\n",
    "from csbdeep.tf import limit_gpu_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow uses all available GPU memory by default, hence it can be useful to limit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit_gpu_memory(fraction=1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Training data\n",
    "\n",
    "Load training data generated via [datagen.ipynb](datagen.ipynb), use 10% as validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y), data_val = train.load_data('my_training_data.npz', validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = X.shape[0]\n",
    "n_val = 0 if data_val is None else data_val[0].shape[0]\n",
    "image_size = X.shape[1:-1]\n",
    "n_dim = len(image_size)\n",
    "n_channel_in = X.shape[-1]\n",
    "n_channel_out = Y.shape[-1]\n",
    "print('# train images:\\t', n_train)\n",
    "print('# val images:\\t', n_val)\n",
    "print('%dD image size:\\t'%n_dim, image_size)\n",
    "print('Channels in:\\t', n_channel_in)\n",
    "print('Channels out:\\t', n_channel_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.plot_utils import plot_some\n",
    "plt.figure(figsize=(10,4))\n",
    "_X,_Y = (X,Y) if data_val is None else data_val\n",
    "plot_some(_X[:5],_Y[:5])\n",
    "plt.suptitle('5 example patches (top row: source, bottom row: target)')\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Model\n",
    "\n",
    "We will now define a neural network based on the deep learning library [Keras](https://keras.io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1**: define neural network for a specific image size (that of the training images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2** *(better)*: model can be applied to other (compatible) image sizes after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = len(image_size)*(None,) + (n_channel_in,)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic prediction\n",
    "\n",
    "Decide whether to use a model for probabilistic prediction or typical regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilistic = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "Our neural network architecture is based on *U-Net* [1] and *residual* learning [2].  \n",
    "Please see our [supplemental material](https://www.biorxiv.org/content/early/2017/12/19/236463.figures-only) for further details.\n",
    "\n",
    "[1] Olaf Ronneberger, Philipp Fischer, Thomas Brox, *U-Net: Convolutional Networks for Biomedical Image Segmentation*, MICCAI 2015.  \n",
    "[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. *Deep Residual Learning for Image Recognition*, CVPR 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nets.common_model(\n",
    "    n_dim         = len(image_size),\n",
    "    n_channel_out = n_channel_out,\n",
    "    prob_out      = probabilistic,\n",
    "    residual      = True and (n_channel_in == n_channel_out),\n",
    "    # U-Net parameters:\n",
    "    n_depth       = 2,\n",
    "    kern_size     = 5 if n_dim==2 else 3,\n",
    "    n_first       = 32,\n",
    ")(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `csbdeep.nets.net_model` to built models with more flexibility, or build your own Keras model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Training\n",
    "\n",
    "See [Keras Documentation](https://keras.io) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "If you have chosen a network architecture for probabilistic prediction (`probabilistic = True`), you need to use the probabilistic **`laplace`** loss. Otherwise, you can use the standard **`mse`** (*mean squared error*) or **`mae`** (*mean absolute error*) losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'laplace' if probabilistic else 'mae'\n",
    "\n",
    "# check\n",
    "if not( model.output_shape[-1] == (2 if probabilistic else 1)*Y.shape[-1] ):\n",
    "    raise ValueError('number of input and output channels does not match.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "The optimization algorithm to minimize the loss function during training. We have always used [Adam](https://keras.io/optimizers/#adam) with a learning rate of `0.0004`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "optimizer = Adam(lr=0.0004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model for training and choose callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `train.prepare_model` will [compile](https://keras.io/models/model/#compile) the model and return a list of [callbacks](https://keras.io/callbacks/) to be used during traning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = train.prepare_model(model,optimizer,loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ModelCheckpoint](https://keras.io/callbacks/#modelcheckpoint) callback to save model during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "callbacks.append(ModelCheckpoint('my_model_best.h5', save_best_only=True, save_weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau) callback to automatically lower learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "callbacks.append(ReduceLROnPlateau(factor=0.5, patience=10, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor training progress with [TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.tf import MyTensorBoard\n",
    "callbacks.append(MyTensorBoard(log_dir='./logs/my_model', n_images=3, write_images=True, prob_out=(loss=='laplace')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start TensorBoard e.g. with **`tensorboard --logdir=./logs --reload-interval=2`** and connect to [http://localhost:6006/](http://localhost:6006/) with your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start actual training with  [model.fit](https://keras.io/models/model/#fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important parameters to choose are the number of `epochs` and the `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X,Y, validation_data=data_val,\n",
    "                    epochs=100,\n",
    "                    batch_size=16,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training history (available in TensorBoard even during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(history.history.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.plot_utils import plot_history\n",
    "plt.figure(figsize=(16,5))\n",
    "if data_val is None:\n",
    "    plot_history(history,['loss'],['mse','mae']);\n",
    "else:\n",
    "    plot_history(history,['loss','val_loss'],['mse','val_mse','mae','val_mae']);\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show example results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "_P = model.predict(_X[:5])\n",
    "if probabilistic:\n",
    "    _P = _P[...,:(_P.shape[-1]//2)]\n",
    "plot_some(_X[:5],_Y[:5],_P,pmax=99.5)\n",
    "plt.suptitle('5 example patches\\n'+\n",
    "             'top row: input (source),  '+\n",
    "             'middle row: target (ground truth),  '+\n",
    "             'bottom row: predicted from source')\n",
    "#plt.tight_layout()\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save final model in the same way as in `ModelCheckpoint` callback above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_last.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model to be used with CSBDeep **Fiji** plugins and **KNIME** workflows\n",
    "See https://github.com/CSBDeep/CSBDeep/wiki/Your-Model-in-Fiji for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.tf import export_SavedModel\n",
    "export_SavedModel(model,'my_model',format='zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
