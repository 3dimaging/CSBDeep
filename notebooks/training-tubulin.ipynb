{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Reconstruction of microtubular structures via synthetic generative models \n",
    "\n",
    "## Notes \n",
    "\n",
    "- Training data was generated via synthetic models of tubules and the image formation process\n",
    "- Here we use only a subset of the training data such that the training time is affordable ( < 10 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import csbdeep\n",
    "from csbdeep import train\n",
    "from csbdeep import nets\n",
    "from csbdeep.tf import limit_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow grabs all memory by default, so we limit it to use only 1/4 of all memory\n",
    "# this allows other notebooks/processes to run code on the gpu even without restarting this kernel\n",
    "limit_memory(.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y),data_val = train.load_data(\n",
    "    'training_data/andi_tubulin.npz',\n",
    "    validation_split=0.05,\n",
    "    n_images=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = X.shape[0]\n",
    "n_val = 0 if data_val is None else data_val[0].shape[0]\n",
    "image_size = X.shape[1:-1]\n",
    "n_dim = len(image_size)\n",
    "n_channel_in = X.shape[-1]\n",
    "n_channel_out = Y.shape[-1]\n",
    "print('# train images:\\t', n_train)\n",
    "print('# val images:\\t', n_val)\n",
    "print('%dD image size:\\t'%n_dim, image_size)\n",
    "print('Channels in:\\t', n_channel_in)\n",
    "print('Channels out:\\t', n_channel_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.plot_utils import plot_some\n",
    "# first row: input. second row: ground truth\n",
    "plt.figure(figsize=(12,5))\n",
    "_X,_Y = (X,Y) if data_val is None else data_val\n",
    "plot_some(_X[:5],_Y[:5],pmax=99.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "We will now define a neural network based on the deep learning library [Keras](https://keras.io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1**: define neural network for a specific image size (that of the training images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2** *(better)*: model can be applied to other (compatible) image sizes after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = len(image_size)*(None,) + (n_channel_in,)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "Our neural network architecture is based on *U-Net* [1] and *residual* learning [2].  \n",
    "Please see our supplemental material for further details.\n",
    "\n",
    "[1] Olaf Ronneberger, Philipp Fischer, Thomas Brox, *U-Net: Convolutional Networks for Biomedical Image Segmentation*, MICCAI 2015.  \n",
    "[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. *Deep Residual Learning for Image Recognition*, CVPR 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilistic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nets.common_model(\n",
    "    n_dim         = len(image_size),\n",
    "    n_channel_out = n_channel_out,\n",
    "    prob_out      = probabilistic,\n",
    "    residual      = True and (n_channel_in == n_channel_out),\n",
    "    # U-Net parameters:\n",
    "    n_depth       = 2,\n",
    "    kern_size     = 5 if n_dim==2 else 3,\n",
    "    n_first       = 32,\n",
    ")(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `csbdeep.nets.net_model` to built models with more flexibility, or build your own Keras model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "\n",
    "# Training\n",
    "\n",
    "See [Keras Documentation](https://keras.io) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "If you have chosen a network architecture for probabilistic prediction (`probabilistic = True`), you need to use the probabilistic **`laplace`** loss. Otherwise, you can use the standard **`mse`** (*mean squared error*) or **`mae`** (*mean absolute error*) losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'laplace' if probabilistic else 'mse'\n",
    "\n",
    "# check\n",
    "if not( model.output_shape[-1] == (2 if probabilistic else 1)*Y.shape[-1] ):\n",
    "    raise ValueError('number of input and output channels does not match.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "The optimization algorithm to minimize the loss function during training. We have always used [Adam](https://keras.io/optimizers/#adam) with a learning rate of `0.0004`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "optimizer = Adam(lr=0.0004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model for training and choose callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `prepare_model` will [compile](https://keras.io/models/model/#compile) the model and return a list of [callbacks](https://keras.io/callbacks/) to be used during traning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, `prepare_model` offers the option to weigh *\"foreground\"* (fg) and *\"background\"* (bg) pixels differently in the loss functions (at the beginning of training). We found that this often leads to improved results, because there are typically many more bg than fg pixels.\n",
    "To take advantage of this, you need to provide the argument `loss_bg_thresh` that defines the threshold between foreground and background pixels, and also provide the labeled data via argument `Y`.\n",
    "\n",
    "The decay parameter `loss_bg_decay` specifies how long the weighting should be active during training. We typically used a value of `0.06`, which means that the effect is effectively disabled after 10-15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = train.prepare_model(model,optimizer,loss)\n",
    "callbacks = train.prepare_model(model,optimizer,loss, loss_bg_thresh=0.3,loss_bg_decay=0.02,Y=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ModelCheckpoint](https://keras.io/callbacks/#modelcheckpoint) callback to save model during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "callbacks.append(ModelCheckpoint('my_model_best.h5', save_best_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau) callback to automatically lower learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "callbacks.append(ReduceLROnPlateau(factor=0.5, patience=10, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor training progress with [TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.tf import MyTensorBoard\n",
    "callbacks.append(MyTensorBoard(log_dir='./logs/tubulin', n_images=3, write_images=True, prob_out=(loss=='laplace')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start TensorBoard e.g. with **`tensorboard --logdir=./logs --reload-interval=2`** and connect to [http://localhost:6006/](http://localhost:6006/) with your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training with  [model.fit](https://keras.io/models/model/#fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important parameters to choose are the number of `epochs` and the `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X,Y, validation_data=data_val,\n",
    "                    epochs=60,\n",
    "                    batch_size=16,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training history (available in TensorBoard even during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(history.history.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.plot_utils import plot_history\n",
    "plt.figure(figsize=(16,5))\n",
    "if data_val is None:\n",
    "    plot_history(history,['loss'],['mse','mae']);\n",
    "else:\n",
    "    plot_history(history,['loss','val_loss'],['mse','val_mse','mae','val_mae']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show example results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "_P = model.predict(_X[:5])\n",
    "if probabilistic:\n",
    "    _P = _P[...,:(_P.shape[-1]//2)]\n",
    "plot_some(_X[:5],_Y[:5],_P,pmax=99.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save final model in the same way as in `ModelCheckpoint` callback above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_last.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export model to be used with CSBDeep **Fiji** plugins and **KNIME** workflows\n",
    "See https://github.com/CSBDeep/CSBDeep/wiki/Your-Model-in-Fiji for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.tf import export_SavedModel\n",
    "export_SavedModel(model,'my_model',format='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
