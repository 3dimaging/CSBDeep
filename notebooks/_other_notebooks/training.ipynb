{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#import os, sys\n",
    "\n",
    "import csbdeep\n",
    "from csbdeep import train\n",
    "from csbdeep import nets\n",
    "#from csbdeep import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f = np.load('/home/uschmidt/research/csbdeep/csbdeep_experiments/experiments/tribolium/training/large_cx_0_1_2_cy_3_nz_16/train/data_label.npz')\n",
    "\n",
    "np.savez('tribolium.npz',X=f['X'][:500],Y=f['Y'][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh *.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y),data_val = train.load_data(\n",
    "    #'/home/uschmidt/research/csbdeep/csbdeep_experiments/experiments/tribolium/training/large_cx_0_1_2_cy_3_nz_16/train/data_label.npz',\n",
    "    #\n",
    "    #'/home/uschmidt/research/csbdeep/csbdeep_experiments/experiments/tribolium/training/large_cx_0_1_2_cy_3_nz_16/test/data_label.npz',\n",
    "    '/home/uschmidt/research/csbdeep/csbdeep_experiments/experiments/andi_tubulin/training/width_6_pert_vary/test/data_label.npz',\n",
    "    #'/home/uschmidt/research/csbdeep/csbdeep_experiments/experiments/isonet_retina/training/subsample_10.20_augment/test/data_label.npz',\n",
    "    validation_split=0.10,\n",
    "    n_images=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = X.shape[0]\n",
    "n_val = 0 if data_val is None else data_val[0].shape[0]\n",
    "image_size = X.shape[1:-1]\n",
    "n_dim = len(image_size)\n",
    "n_channel_in = X.shape[-1]\n",
    "n_channel_out = Y.shape[-1]\n",
    "print('# train images:\\t', n_train)\n",
    "print('# val images:\\t', n_val)\n",
    "print('%dD image size:\\t'%n_dim, image_size)\n",
    "print('Channels in:\\t', n_channel_in)\n",
    "print('Channels out:\\t', n_channel_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.plot_utils import plot_some\n",
    "# first row: input. second row: ground truth\n",
    "plt.figure(figsize=(12,5))\n",
    "_X,_Y = (X,Y) if data_val is None else data_val\n",
    "plot_some(_X[:5],_Y[:5],pmax=99.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "We will now define a neural network based on the deep learning library [Keras](https://keras.io)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1**: define neural network for a specific image size (that of the training images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2** *(better)*: model can be applied to other (compatible) image sizes after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = len(image_size)*(None,) + (n_channel_in,)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model\n",
    "\n",
    "- based on u-net: ref\n",
    "- resnet: ref\n",
    "- see our supplement for details. table X gives the details for the models in our paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilistic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nets.common_model(\n",
    "    n_dim         = len(image_size),\n",
    "    n_channel_out = n_channel_out,\n",
    "    prob_out      = probabilistic,\n",
    "    residual      = True and (n_channel_in == n_channel_out),\n",
    "    # U-Net parameters:\n",
    "    n_depth       = 2,\n",
    "    kern_size     = 5 if n_dim==2 else 3,\n",
    "    n_first       = 32,\n",
    ")(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see doc\n",
    "nets.common_model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative (equivalent) way to define model by shorthand name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = nets.common_model_by_name('resunet3p_1_3_16_1out')(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see doc\n",
    "nets.common_model_by_name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `csbdeep.nets.net_model` to built models with more flexibility, or build your own Keras model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "See [Keras Documentation](https://keras.io) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "If you have chosen a network architecture for probabilistic prediction (`prob_out = True`), you need to use the probabilistic **`laplace`** loss. Otherwise, you can use the standard **`mse`** (*mean squared error*) or **`mae`** (*mean absolute error*) losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'laplace' if probabilistic else 'mse'\n",
    "\n",
    "# check\n",
    "if not( model.output_shape[-1] == (2 if probabilistic else 1)*Y.shape[-1] ):\n",
    "    raise ValueError('number of input and output channels does not match.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "The optimization algorithm to minimize the loss function during training. We have always used [Adam](https://keras.io/optimizers/#adam) with a learning rate of `0.0004`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "optimizer = Adam(lr=0.0004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model for training and choose callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `prepare_model` will [compile](https://keras.io/models/model/#compile) the model and return a list of [callbacks](https://keras.io/callbacks/) to be used during traning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = train.prepare_model(model,optimizer,loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, `prepare_model` offers the option to weigh *\"foreground\"* (fg) and *\"background\"* (bg) pixels differently in the loss functions (at the beginning of training). We found that this often leads to improved results, because there are typically many more bg than fg pixels.\n",
    "To take advantage of this, you need to provide the argument `loss_bg_thresh` that defines the threshold between foreground and background pixels, and also provide the labeled data via argument `Y`.\n",
    "\n",
    "The decay parameter `loss_bg_decay` specifies how long long the weighting should be active during training. We typically used a value of `0.06`, which means that the effect is effectively disabled after 10-15 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bg_thresh = 0.4\n",
    "loss_bg_decay = 0.02\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "##\n",
    "epochs = np.arange(1+n_epochs)\n",
    "alphas = np.zeros(1+n_epochs)\n",
    "alphas[0] = 1.0\n",
    "for i in range(1,n_epochs):\n",
    "    alphas[i] = alphas[i-1] / (1. + loss_bg_decay * i)\n",
    "\n",
    "##\n",
    "#half_life = 3\n",
    "#gamma = np.log(2) / half_life\n",
    "#new = np.exp(- gamma * (epochs))\n",
    "\n",
    "\n",
    "freq = np.mean(Y > loss_bg_thresh)\n",
    "w1 = 0.5 / (0.1 + (1 - freq))\n",
    "w2 = 0.5 / (0.1 +      freq)\n",
    "\n",
    "k1 = [(a * w1 + (1 - a)) for a in alphas]\n",
    "k2 = [(a * w2 + (1 - a)) for a in alphas]\n",
    "\n",
    "plt.figure(figsize=(13,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs,alphas,'.-');\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs,k1,'.-',label='bg');\n",
    "plt.plot(epochs,k2,'.-',label='fg');\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIXME: replace `loss_bg_decay` with `loss_bg_halflife`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = train.prepare_model(model,optimizer,loss, loss_bg_thresh=0.3,loss_bg_decay=loss_bg_decay,Y=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ModelCheckpoint](https://keras.io/callbacks/#modelcheckpoint) callback to save model during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "callbacks.append(ModelCheckpoint('my_model_best.h5', save_best_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau) callback to automatically lower learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "callbacks.append(ReduceLROnPlateau(factor=0.5, patience=10, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor training progress with [TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.tf import MyTensorBoard\n",
    "callbacks.append(MyTensorBoard(log_dir='./logs', n_images=3, write_images=True, prob_out=(loss=='laplace')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start TensorBoard e.g. with **`tensorboard --logdir=./logs --reload-interval=2`** and connect to [http://localhost:6006/]() with your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training with  [model.fit](https://keras.io/models/model/#fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important parameters to choose are the number of `epochs` and the `batch_size`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.callbacks import LambdaCallback\n",
    "from IPython import display\n",
    "\n",
    "def plot_callback(func,p=20):\n",
    "    def plot_epoch_end(epoch,logs):\n",
    "        if epoch == 0 or (epoch+1) % p == 0:\n",
    "            plt.clf(); func(); # plt.title('epoch %d' % (epoch+1))\n",
    "            display.clear_output(wait=True); display.display(plt.gcf())\n",
    "    def clear(*args):\n",
    "        plt.clf()\n",
    "    return LambdaCallback(on_epoch_end=plot_epoch_end,on_train_end=clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from csbdeep.plot_utils import plot_foo    \n",
    "def bar():\n",
    "    plt.figure(figsize=(12,7))\n",
    "    _P = model.predict(_X[:5])\n",
    "    if probabilistic:\n",
    "        _P = _P[...,:(_P.shape[-1]//2)]\n",
    "    plot_foo(_X[:5],_Y[:5],_P,pmax=99.99);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "callbacks = []\n",
    "callbacks.append( TQDMNotebookCallback() )\n",
    "callbacks.append( plot_callback(bar,5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X,Y, validation_data=data_val,\n",
    "                    epochs=100,\n",
    "                    batch_size=16,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training history (available in TensorBoard even during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(history.history.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.plot_utils import plot_history\n",
    "plt.figure(figsize=(16,5))\n",
    "if data_val is None:\n",
    "    plot_history(history,['loss'],['mse','mae']);\n",
    "else:\n",
    "    plot_history(history,['loss','val_loss'],['mse','val_mse','mae','val_mae']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show example results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "_P = model.predict(_X[:5])\n",
    "if probabilistic:\n",
    "    _P = _P[...,:(_P.shape[-1]//2)]\n",
    "plot_some(_X[:5],_Y[:5],_P,pmax=99.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save final model in the same way as in `ModelCheckpoint` callback above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_last.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: export model to be used with CSBDeep **Fiji** plugins and **KNIME** workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.tf import export_SavedModel\n",
    "export_SavedModel(model,'my_model',format='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: refer to https://github.com/CSBDeep/CSBDeep/wiki/Your-Model-in-Fiji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
