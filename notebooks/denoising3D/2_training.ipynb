{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Demo: Neural network training for denoising of *Tribolium castaneum*\n",
    "\n",
    "### Notes \n",
    "\n",
    "- Assumes that training data was already generated via [1_datagen.ipynb](1_datagen.ipynb) and has been saved to disk to the file ``my_training_data.npz``.\n",
    "- Training a neural network for actual use should be done on more (representative) data and with more training time.\n",
    "- Documentation available: http://csbdeep.bioimagecomputing.com/doc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.rendered_html { font-size: 16px; }</style>\"))\n",
    "import os\n",
    "from tifffile import imread\n",
    "\n",
    "import csbdeep\n",
    "from csbdeep.utils import axes_dict, plot_some\n",
    "from csbdeep.io import load_training_data\n",
    "from csbdeep.models import Config, CARE\n",
    "from csbdeep.utils.tf import limit_gpu_memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow uses all available GPU memory by default, hence it can be useful to limit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit_gpu_memory(fraction=1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Training data\n",
    "\n",
    "Load training data generated via [1_datagen.ipynb](1_datagen.ipynb), use 10% as validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y), (X_val,Y_val), axes = load_training_data('my_training_data.npz', validation_split=0.1)\n",
    "ax = axes_dict(axes)\n",
    "\n",
    "n_train, n_val = len(X), len(X_val)\n",
    "image_size = tuple(X.shape[i] for i in ((ax['Z'],ax['Y'],ax['X']) if (ax['Z'] is not None) else (ax['Y'],ax['X'])))\n",
    "n_dim = len(image_size)\n",
    "n_channel_in, n_channel_out = X.shape[ax['C']], Y.shape[ax['C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of training images:\\t', n_train)\n",
    "print('number of validation images:\\t', n_val)\n",
    "print('image size (%dD):\\t\\t'%n_dim, image_size)\n",
    "print('axes:\\t\\t\\t\\t', axes)\n",
    "print('Channels in / out:\\t\\t', n_channel_in, '/', n_channel_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plot_some(X_val[:5],Y_val[:5])\n",
    "plt.suptitle('5 example validation patches (top row: source, bottom row: target)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we construct the actual CARE model, we have to define its (training) configuration via a `Config` object, that includes things like \n",
    "\n",
    "* type of network \n",
    "* learning rate\n",
    "* number of steps per epoch\n",
    "* loss function  \n",
    "* whether the model is probabilistic or not\n",
    "\n",
    "The defaults should be sensible in many cases, so a change should only be necessary if the training process fails.  \n",
    "\n",
    "Note that for this notebook we use a very small number of iterations per epoch for immediate feedvback, wheras for a properly trained model this number should be increased (e.g. `train_seps_per_epoch =400`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(axes, n_channel_in, n_channel_out, train_epochs =30, train_steps_per_epoch=20)\n",
    "print(config)\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a CARE model based on chosen options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CARE(config, 'my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually train the model, which may take some time.\n",
    "\n",
    "To monitor the progress during training one can use [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard), by starting it from the current working directory:\n",
    "\n",
    "`tensorboard --logdir=. --reload-interval=2`\n",
    "\n",
    "and then connect to [http://localhost:6006/](http://localhost:6006/) with your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.train(X,Y, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot final training history (available in TensorBoard during training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.utils import plot_history\n",
    "print(sorted(list(history.history.keys())))\n",
    "plt.figure(figsize=(16,5))\n",
    "plot_history(history,['loss','val_loss'],['mse','val_mse','mae','val_mae']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "Example results for validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights() # load best weights according to validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "_P = model.keras_model.predict(X_val[:5])\n",
    "if config.probabilistic:\n",
    "    _P = _P[...,:(_P.shape[-1]//2)]\n",
    "plot_some(X_val[:5],Y_val[:5],_P,pmax=99.5)\n",
    "plt.suptitle('5 example validation patches\\n'       +\n",
    "             'top row: input (source),  '           +\n",
    "             'middle row: target (ground truth),  ' +\n",
    "             'bottom row: predicted from source')\n",
    "#plt.tight_layout()\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Export model to be used with CSBDeep **Fiji** plugins and **KNIME** workflows\n",
    "\n",
    "See https://github.com/CSBDeep/CSBDeep/wiki/Your-Model-in-Fiji for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export_TF()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
