{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Demo: Application of trained neural network for isotropic reconstruction of ...\n",
    "\n",
    "### Notes \n",
    "\n",
    "- Assumes that training was already completed via [training.ipynb](training.ipynb).\n",
    "- The trained CARE network is here applied to the same image that the model was trained on (data generated via [datagen.ipynb](datagen.ipynb)).  \n",
    "Of course, in practice one would typically use it to restore images that the model hasn't seen during training.\n",
    "- Documentation available: http://csbdeep.bioimagecomputing.com/doc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "from tifffile import imread\n",
    "from csbdeep.models import CARE\n",
    "from csbdeep.predict import PercentileNormalizer, PadAndCropResizer\n",
    "from csbdeep.plot_utils import plot_some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    import gputools\n",
    "#    from csbdeep.tf import limit_gpu_memory\n",
    "#    limit_gpu_memory(fraction=3/4)    \n",
    "#except ImportError:\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expect data like this:\n",
    "\n",
    "    raw_data\n",
    "    ├── test_stacks_sub_4\n",
    "    │   └── stack_low_sub_4_03.tif\n",
    "    └── training_stacks\n",
    "        ├── high\n",
    "        │   ├── stack_00.tif\n",
    "        │   ├── stack_01.tif\n",
    "        │   └── stack_02.tif\n",
    "        └── low\n",
    "            ├── stack_00.tif\n",
    "            ├── stack_01.tif\n",
    "            └── stack_02.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Raw 3D image stack with low z resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = imread('raw_data/test_stacks_sub_4/stack_low_sub_4_03.tif')\n",
    "axes = 'ZYX'\n",
    "subsample = 4\n",
    "print('image size       =', x.shape)\n",
    "print('image axes       =', axes)\n",
    "print('subsample factor =', subsample)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(x[:,:,0],aspect=subsample)\n",
    "plt.axis('off')\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Model\n",
    "\n",
    "Load trained model (located in folder `my_model`) from disk.  \n",
    "The configuration was saved during training and is automatically loaded when `CARE` is initialized with `config=None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CARE(config=None, name='my_model')\n",
    "model.load_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select appropriate normalization\n",
    "- Choose how to resize the image to be able to apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = PercentileNormalizer(1,99.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply CARE network to raw image\n",
    "\n",
    "Predict the restored image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import zoom\n",
    "from csbdeep.utils import axes_dict\n",
    "factors = np.ones(x.ndim)\n",
    "factors[axes_dict(axes)['Z']] = subsample\n",
    "x_upscaled = zoom(x,factors,order=1)\n",
    "x_upscaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "restored = model.predict(x_upscaled, axes, normalizer, n_tiles=8)\n",
    "\n",
    "print('input  (%s) = %s' % (axes, str(x_upscaled.shape)))\n",
    "print('output (%s) = %s' % (axes, str(restored.shape)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.utils import save_tiff_imagej_compatible\n",
    "save_tiff_imagej_compatible('restored_stack_low_sub_4_03.tif',restored,axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Reconstructed image via CARE network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(x_upscaled[:,:,0])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(restored[:,:,0])\n",
    "plt.axis('off')\n",
    "None;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
